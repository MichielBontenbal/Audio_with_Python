{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Visualising audio with Python\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1100/1*Zx9QAMPzxhama9O4q9xWXg.jpeg\" width=\"600\"/>\n",
    "\n",
    "This notebook is intended to be an introduction for anyone interested in using python to interperate audio data.\n",
    "\n",
    "## Contents\n",
    "0. Installing and importing packages\n",
    "1. Some theory\n",
    "2. Reading in Audio Files and creating a waveform and sound graph\n",
    "3. Creating a Spectogram\n",
    "4. Creating a Mel Spectogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installing and importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T19:07:26.185389Z",
     "iopub.status.busy": "2022-05-29T19:07:26.185048Z",
     "iopub.status.idle": "2022-05-29T19:07:29.041910Z",
     "shell.execute_reply": "2022-05-29T19:07:29.041158Z",
     "shell.execute_reply.started": "2022-05-29T19:07:26.185301Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "sns.set_theme(style=\"white\", palette=None)\n",
    "color_pal = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "color_cycle = cycle(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Some theory \n",
    "\n",
    "Terms to know for Audio in Digital Form:\n",
    "\n",
    "### Frequency (Hz)\n",
    "- Frequency describes the differences of wave lengths.\n",
    "- We interperate frequency has high and low pitches.\n",
    "\n",
    "<img src=\"https://uploads-cdn.omnicalculator.com/images/britannica-wave-frequency.jpg\" width=\"400\"/>\n",
    "\n",
    "### Intensity (db / power)\n",
    "- Intensity describes the amplitude (height) of the wave.\n",
    "\n",
    "<img src=\"https://ars.els-cdn.com/content/image/3-s2.0-B9780124722804500162-f13-15-9780124722804.gif\" width=\"400\"/>\n",
    "\n",
    "### Sample Rate\n",
    "- Sample rate is specific to how the computer reads in the audio file.\n",
    "- Think of it as the \"resolution\" of the audio.\n",
    "\n",
    "<img src=\"https://www.headphonesty.com/wp-content/uploads/2019/07/Sample-Rate-Bit-Depth-and-Bit-Rate.jpeg\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading in Audio Files and creating a waveform and sound graph\n",
    "There are many types of audio files: `mp3`, `wav`, `m4a`, `flac`, `ogg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:17:05.56168Z",
     "iopub.status.busy": "2022-02-19T21:17:05.560814Z",
     "iopub.status.idle": "2022-02-19T21:17:05.592357Z",
     "shell.execute_reply": "2022-02-19T21:17:05.591717Z",
     "shell.execute_reply.started": "2022-02-19T21:17:05.561631Z"
    }
   },
   "outputs": [],
   "source": [
    "audio_files = glob('*.wav')\n",
    "print(audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:17:31.840115Z",
     "iopub.status.busy": "2022-02-19T21:17:31.83982Z",
     "iopub.status.idle": "2022-02-19T21:17:31.869235Z",
     "shell.execute_reply": "2022-02-19T21:17:31.868431Z",
     "shell.execute_reply.started": "2022-02-19T21:17:31.840083Z"
    }
   },
   "outputs": [],
   "source": [
    "# Play audio file\n",
    "audio_path = audio_files[1]\n",
    "IPython.display.Audio(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:19:29.501743Z",
     "iopub.status.busy": "2022-02-19T21:19:29.501419Z",
     "iopub.status.idle": "2022-02-19T21:19:29.678071Z",
     "shell.execute_reply": "2022-02-19T21:19:29.677344Z",
     "shell.execute_reply.started": "2022-02-19T21:19:29.501714Z"
    }
   },
   "outputs": [],
   "source": [
    "y, sr = librosa.load(audio_path)\n",
    "print(f'y: {y[:10]}')\n",
    "print(f'shape y: {y.shape}')\n",
    "print(f'sample rate: {sr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:21:03.374852Z",
     "iopub.status.busy": "2022-02-19T21:21:03.374562Z",
     "iopub.status.idle": "2022-02-19T21:21:03.642317Z",
     "shell.execute_reply": "2022-02-19T21:21:03.641635Z",
     "shell.execute_reply.started": "2022-02-19T21:21:03.374821Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pd.Series(y).plot(figsize=(15, 5),\n",
    "                  lw=1,\n",
    "                  title='Raw Audio Example',\n",
    "                 color=color_pal[0])\n",
    "plt.show()\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:23:54.390065Z",
     "iopub.status.busy": "2022-02-19T21:23:54.389489Z",
     "iopub.status.idle": "2022-02-19T21:23:54.639935Z",
     "shell.execute_reply": "2022-02-19T21:23:54.63938Z",
     "shell.execute_reply.started": "2022-02-19T21:23:54.390029Z"
    }
   },
   "outputs": [],
   "source": [
    "# Trimming leading/lagging silence\n",
    "y_trimmed, _ = librosa.effects.trim(y, top_db=10)\n",
    "pd.Series(y_trimmed).plot(figsize=(15, 5),\n",
    "                  lw=1,\n",
    "                  title='Raw Audio Trimmed Example',\n",
    "                 color=color_pal[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:25:40.965344Z",
     "iopub.status.busy": "2022-02-19T21:25:40.965005Z",
     "iopub.status.idle": "2022-02-19T21:25:41.1966Z",
     "shell.execute_reply": "2022-02-19T21:25:41.195712Z",
     "shell.execute_reply.started": "2022-02-19T21:25:40.965307Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(y[30000:30500]).plot(figsize=(10, 5),\n",
    "                  lw=1,\n",
    "                  title='Raw Audio Zoomed In Example',\n",
    "                 color=color_pal[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating a Spectogram\n",
    "\n",
    "A spectrogram is a diagram with on the y-axis the frequency (Herz) and on the x-axis the time. The intensity of the colors give a indication of the energy of a certain frequency. \n",
    "\n",
    "Spectrograms are mostly used to visualise sounds with a low frequency as the image below shows.\n",
    "\n",
    "Spectrograms are generated from audio samples using the Fourier Transform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:28:11.620901Z",
     "iopub.status.busy": "2022-02-19T21:28:11.620131Z",
     "iopub.status.idle": "2022-02-19T21:28:11.63607Z",
     "shell.execute_reply": "2022-02-19T21:28:11.635291Z",
     "shell.execute_reply.started": "2022-02-19T21:28:11.620858Z"
    }
   },
   "outputs": [],
   "source": [
    "D = librosa.stft(y)\n",
    "S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "print(S_db.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:30:40.191221Z",
     "iopub.status.busy": "2022-02-19T21:30:40.190957Z",
     "iopub.status.idle": "2022-02-19T21:30:40.622933Z",
     "shell.execute_reply": "2022-02-19T21:30:40.622047Z",
     "shell.execute_reply.started": "2022-02-19T21:30:40.191193Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the transformed audio data\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "img = librosa.display.specshow(S_db,\n",
    "                              x_axis='time',\n",
    "                              y_axis='log',\n",
    "                              ax=ax)\n",
    "ax.set_title('Spectogram Example', fontsize=20)\n",
    "fig.colorbar(img, ax=ax, format=f'%0.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating a Mel Spectogram\n",
    "\n",
    "Mel spectrogram is a likewise a spectrogram. But look at the y-axis: it's logarithmic.\n",
    "\n",
    "This is useful as we humans also perceive frequencies. Take for example 100 Hz vs 200 Hz, we can hear the difference. However, for humans 10000 Hz vs 10100 Hz is much more difficult to hear.\n",
    "\n",
    "See also: https://en.wikipedia.org/wiki/Mel_scale\n",
    "\n",
    "#### Differences between Mel Spectrogram and Spectrogram:\n",
    "\n",
    "Mel Spectrogram:\n",
    "- uses Mel scale (= a log scale) instead of linear frequency on the y-axis\n",
    "- it uses decibel scale (=a log scale) instead of amplitude to indicate colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:37:18.363461Z",
     "iopub.status.busy": "2022-02-19T21:37:18.363181Z",
     "iopub.status.idle": "2022-02-19T21:37:18.387745Z",
     "shell.execute_reply": "2022-02-19T21:37:18.38681Z",
     "shell.execute_reply.started": "2022-02-19T21:37:18.363427Z"
    }
   },
   "outputs": [],
   "source": [
    "S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128 * 2,)#n_mels is the number of Mel bins used aka frequency bands)\n",
    "S_db_mel = librosa.amplitude_to_db(S, ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:37:18.726563Z",
     "iopub.status.busy": "2022-02-19T21:37:18.726294Z",
     "iopub.status.idle": "2022-02-19T21:37:19.040674Z",
     "shell.execute_reply": "2022-02-19T21:37:19.039786Z",
     "shell.execute_reply.started": "2022-02-19T21:37:18.726533Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# Plot the mel spectogram\n",
    "img = librosa.display.specshow(S_db_mel,\n",
    "                              x_axis='time',\n",
    "                              y_axis='log',\n",
    "                              ax=ax)\n",
    "ax.set_title('Mel Spectogram Example', fontsize=20)\n",
    "fig.colorbar(img, ax=ax, format=f'%0.2f')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
